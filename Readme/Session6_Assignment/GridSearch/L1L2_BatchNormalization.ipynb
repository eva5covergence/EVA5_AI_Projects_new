{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L1L2_BatchNormalization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f384ec9061843a2a2a993b24077b3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_40aba8082de345aab381e6cf9aa5209f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5d13249f6cdd4ae3a72d19d7a8d24b8d",
              "IPY_MODEL_d1fe44fe47b8437f97be1e53ab2fae90"
            ]
          }
        },
        "40aba8082de345aab381e6cf9aa5209f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d13249f6cdd4ae3a72d19d7a8d24b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6ee67a266dbd44c58ade20dc9343dcd0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3ef8e815f344d03a9d553302c776685"
          }
        },
        "d1fe44fe47b8437f97be1e53ab2fae90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9e57c45b0bfa43c8862c2c674a151192",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:20&lt;00:00, 1048012.91it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f99e65bbba5a447d87c6e2fcf3130050"
          }
        },
        "6ee67a266dbd44c58ade20dc9343dcd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3ef8e815f344d03a9d553302c776685": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e57c45b0bfa43c8862c2c674a151192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f99e65bbba5a447d87c6e2fcf3130050": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b7b2cce7e6e45df989edac151e555ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9750a7dc50c34ada9bf6dd8cddddd1ec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_07b6f290b52c41c0a7967bde215475e7",
              "IPY_MODEL_d2cb615bc2354c59b697eff17d86d485"
            ]
          }
        },
        "9750a7dc50c34ada9bf6dd8cddddd1ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07b6f290b52c41c0a7967bde215475e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ad4d593505140b6b7830453bd6e10a4",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_37f560e3e83245338a94b2ee7f2f6523"
          }
        },
        "d2cb615bc2354c59b697eff17d86d485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bd3d0ac7e51a4f02b20900a5de5bf632",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/28881 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41bf7e9cd4484e579ef5f53004c43033"
          }
        },
        "1ad4d593505140b6b7830453bd6e10a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "37f560e3e83245338a94b2ee7f2f6523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd3d0ac7e51a4f02b20900a5de5bf632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41bf7e9cd4484e579ef5f53004c43033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0116b8ce4cf4574848642e925c8344d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a8d40abf01a141e19043c207fc163bdd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_90ec97db7ce142268b01d25eb8ac6cd8",
              "IPY_MODEL_9b201257401d4242bbed89d77c8821c7"
            ]
          }
        },
        "a8d40abf01a141e19043c207fc163bdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90ec97db7ce142268b01d25eb8ac6cd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_98b04a20e2804609b580755acbf82bd1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2bec147b5ad9482383224bc27c9944e1"
          }
        },
        "9b201257401d4242bbed89d77c8821c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_96032a313bd84559a6dea99793f172ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:18&lt;00:00, 533321.38it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a444abde6ace496bb6814b1099a84bb9"
          }
        },
        "98b04a20e2804609b580755acbf82bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2bec147b5ad9482383224bc27c9944e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96032a313bd84559a6dea99793f172ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a444abde6ace496bb6814b1099a84bb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0279db2bf0e34d50af8207981acec975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_26a407a868cc4f30b0c3c09e6e661b90",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d98867621244a538d8e026d80b5270e",
              "IPY_MODEL_d3b3f971288747afb4cd9a91b6dbd884"
            ]
          }
        },
        "26a407a868cc4f30b0c3c09e6e661b90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d98867621244a538d8e026d80b5270e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c2c9dcc249d04869852f19f1a9a07d7c",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fdb5c0d7a4d47c8a09876ce5fc25fef"
          }
        },
        "d3b3f971288747afb4cd9a91b6dbd884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_107b79b07a984ba5905bbce1c83043d5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/4542 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58ef43c4946d4e30a708969b9a82f0f3"
          }
        },
        "c2c9dcc249d04869852f19f1a9a07d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8fdb5c0d7a4d47c8a09876ce5fc25fef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "107b79b07a984ba5905bbce1c83043d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58ef43c4946d4e30a708969b9a82f0f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MWDgf5dUEFk",
        "colab_type": "text"
      },
      "source": [
        "# FineTune_LR_scheduler - S5_v6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zyfvtCFICOU",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Target:\n",
        "\n",
        "1. FineTune LR scheduler. Set LR=0.1 as before but updated StepSize = 12 and Gamma = 0.2\n",
        "\n",
        "# Results:\n",
        "\n",
        "1. Parameters: 7,612\n",
        "2. Best Train Accuracy: 99.41\n",
        "3. Best Test Accuracy: 99.49\n",
        "\n",
        "# Analysis:\n",
        "1. To get best combination values StepSize = 12 and Gamma =0.2, we tried many trails of these two values.\n",
        "2. The intuition behind above values is, we observed the accuracy is gradually increasing till around 10 epochs and getting stall from there. So we would like to update LR around 10-12 epochs.\n",
        "3. We tried with StepSize and Gamma combinations - (10, 0.1), (11, 0.1), (12, 0.1) But didn't help to get the target accuracy consistently at last few epochs.\n",
        "4. So we thought to increase the speed a little bit after 10-12 epochs by updating gamma = 0.2 and tried these StepSize and Gamma combinations - (10, 0.2), (11, 0.2), (12, 0.2) And finaally Stepsize=12, Gamma=0.2 gave best consistency of >=99.4% in the last 3 epochs and hit maximum of 99.49% with less than 8000 parameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO-7t1Y7-hV4",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kH16rnZ7wt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import time "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkgEpHeg6fOH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "eed175b5-d147-4208-83ac-90a5d3707225"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G77NEAIK3PaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "  \n",
        "logger = logging.getLogger(\"\")\n",
        "#logging.basicConfig(level=logging.DEBUG)\n",
        "filename = '/content/drive/My Drive/Final_GridSearch_S_E_EVA5_S5_v6_FineTune_LR_scheduler_final_S6_L1&L2_BN_v3'+time.ctime().replace(' ','_')+'.txt'\n",
        "logging.basicConfig(level = logging.DEBUG, filename = filename)\n",
        "# logger.debug('Loging %s lewel', 'DEBUG')\n",
        "# logger.info('Loging %s lewel', 'INFO')\n",
        "# logger.warning('Loging %s lewel', 'WARN')\n",
        "# logger.error('Loging %s lewel', 'ERROR')\n",
        "# logger.critical('Loging %s lewel', 'CRITICAL')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmcHYOj6hKpj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d36b42df-b73d-4cb1-8b44-50d396af0ab2"
      },
      "source": [
        "time.ctime()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Thu Aug 27 16:56:45 2020'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RlReRL6mDLk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "32178c3f-1b02-4ea1-bb99-ae9e792efdb9"
      },
      "source": [
        "time.ctime().replace(' ','_')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Thu_Aug_27_16:56:47_2020'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky3f_Odl-7um",
        "colab_type": "text"
      },
      "source": [
        "## Data Transformations\n",
        "\n",
        "We first start with defining our data transformations. We need to think what our data is and how can we augment it to correct represent images which it might not see otherwise. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtssFUKb-jqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation((-7.0, 7.0), fill=(1,)),                                   \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQciFYo2B1mO",
        "colab_type": "text"
      },
      "source": [
        "# Dataset and Creating Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4A84rlfDA23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "2f384ec9061843a2a2a993b24077b3ec",
            "40aba8082de345aab381e6cf9aa5209f",
            "5d13249f6cdd4ae3a72d19d7a8d24b8d",
            "d1fe44fe47b8437f97be1e53ab2fae90",
            "6ee67a266dbd44c58ade20dc9343dcd0",
            "d3ef8e815f344d03a9d553302c776685",
            "9e57c45b0bfa43c8862c2c674a151192",
            "f99e65bbba5a447d87c6e2fcf3130050",
            "5b7b2cce7e6e45df989edac151e555ff",
            "9750a7dc50c34ada9bf6dd8cddddd1ec",
            "07b6f290b52c41c0a7967bde215475e7",
            "d2cb615bc2354c59b697eff17d86d485",
            "1ad4d593505140b6b7830453bd6e10a4",
            "37f560e3e83245338a94b2ee7f2f6523",
            "bd3d0ac7e51a4f02b20900a5de5bf632",
            "41bf7e9cd4484e579ef5f53004c43033",
            "d0116b8ce4cf4574848642e925c8344d",
            "a8d40abf01a141e19043c207fc163bdd",
            "90ec97db7ce142268b01d25eb8ac6cd8",
            "9b201257401d4242bbed89d77c8821c7",
            "98b04a20e2804609b580755acbf82bd1",
            "2bec147b5ad9482383224bc27c9944e1",
            "96032a313bd84559a6dea99793f172ac",
            "a444abde6ace496bb6814b1099a84bb9",
            "0279db2bf0e34d50af8207981acec975",
            "26a407a868cc4f30b0c3c09e6e661b90",
            "4d98867621244a538d8e026d80b5270e",
            "d3b3f971288747afb4cd9a91b6dbd884",
            "c2c9dcc249d04869852f19f1a9a07d7c",
            "8fdb5c0d7a4d47c8a09876ce5fc25fef",
            "107b79b07a984ba5905bbce1c83043d5",
            "58ef43c4946d4e30a708969b9a82f0f3"
          ]
        },
        "outputId": "bf9dc7f9-3faf-450b-ca0e-c2f5581c4c55"
      },
      "source": [
        "train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\n",
        "test = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f384ec9061843a2a2a993b24077b3ec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b7b2cce7e6e45df989edac151e555ff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0116b8ce4cf4574848642e925c8344d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0279db2bf0e34d50af8207981acec975",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgldp_3-Dn0c",
        "colab_type": "text"
      },
      "source": [
        "# Dataloader Arguments & Test/Train Dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8OLDR79DrHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "# logger.info(\"CUDA Available?\", cuda)\n",
        "# logger.info(f\"CUDA Available? {cuda}\")\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubQL3H6RJL3h",
        "colab_type": "text"
      },
      "source": [
        "# The model\n",
        "Let's start with the model we first saw"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts6A8MUHg5sA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BatchNorm(nn.BatchNorm2d):\n",
        "    def __init__(self, num_features, eps=1e-05, momentum=0.1, weight=True, bias=True):\n",
        "        super().__init__(num_features, eps=eps, momentum=momentum)\n",
        "        self.weight.data.fill_(1.0)\n",
        "        self.bias.data.fill_(0.0)\n",
        "        self.weight.requires_grad = weight\n",
        "        self.bias.requires_grad = bias\n",
        "\n",
        "\n",
        "class GhostBatchNorm(BatchNorm):\n",
        "    def __init__(self, num_features, num_splits, **kw):\n",
        "        super().__init__(num_features, **kw)\n",
        "        self.num_splits = num_splits\n",
        "        self.register_buffer('running_mean', torch.zeros(num_features * self.num_splits))\n",
        "        self.register_buffer('running_var', torch.ones(num_features * self.num_splits))\n",
        "\n",
        "    def train(self, mode=True):\n",
        "        if (self.training is True) and (mode is False):  # lazily collate stats when we are going to use them\n",
        "            self.running_mean = torch.mean(self.running_mean.view(self.num_splits, self.num_features), dim=0).repeat(\n",
        "                self.num_splits)\n",
        "            self.running_var = torch.mean(self.running_var.view(self.num_splits, self.num_features), dim=0).repeat(\n",
        "                self.num_splits)\n",
        "        return super().train(mode)\n",
        "\n",
        "    def forward(self, input):\n",
        "        N, C, H, W = input.shape\n",
        "        if self.training or not self.track_running_stats:\n",
        "            return F.batch_norm(\n",
        "                input.view(-1, C * self.num_splits, H, W), self.running_mean, self.running_var,\n",
        "                self.weight.repeat(self.num_splits), self.bias.repeat(self.num_splits),\n",
        "                True, self.momentum, self.eps).view(N, C, H, W)\n",
        "        else:\n",
        "            return F.batch_norm(\n",
        "                input, self.running_mean[:self.num_features], self.running_var[:self.num_features],\n",
        "                self.weight, self.bias, False, self.momentum, self.eps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FXQlB9kH1ov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Input Block\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(8)\n",
        "        ) # output_size = 26\n",
        "\n",
        "        # CONVOLUTION BLOCK 1\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16)\n",
        "        ) # output_size = 24\n",
        "\n",
        "        # TRANSITION BLOCK 1\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 12\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=(1, 1), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(8)\n",
        "        ) # output_size = 12\n",
        "\n",
        "        # CONVOLUTION BLOCK 2\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16)\n",
        "        ) # output_size = 10\n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32)\n",
        "        ) # output_size = 8\n",
        "\n",
        "        # OUTPUT BLOCK\n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(10)\n",
        "        ) # output_size = 8\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=8)\n",
        "        ) # output_size = 1\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.convblock5(x)\n",
        "        x = self.convblock6(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3-vp8X9LCWo",
        "colab_type": "text"
      },
      "source": [
        "# Model Params\n",
        "Can't emphasize on how important viewing Model Summary is. \n",
        "Unfortunately, there is no in-built model visualizer, so we have to take external help"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5skB97zIJQQe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "e7aa70b2-6b02-459b-fee5-122e92681c42"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "# logger.info(device)\n",
        "logger.info(f\"Device : {device}\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 26, 26]              72\n",
            "              ReLU-2            [-1, 8, 26, 26]               0\n",
            "       BatchNorm2d-3            [-1, 8, 26, 26]              16\n",
            "            Conv2d-4           [-1, 16, 24, 24]           1,152\n",
            "              ReLU-5           [-1, 16, 24, 24]               0\n",
            "       BatchNorm2d-6           [-1, 16, 24, 24]              32\n",
            "         MaxPool2d-7           [-1, 16, 12, 12]               0\n",
            "            Conv2d-8            [-1, 8, 12, 12]             128\n",
            "              ReLU-9            [-1, 8, 12, 12]               0\n",
            "      BatchNorm2d-10            [-1, 8, 12, 12]              16\n",
            "           Conv2d-11           [-1, 16, 10, 10]           1,152\n",
            "             ReLU-12           [-1, 16, 10, 10]               0\n",
            "      BatchNorm2d-13           [-1, 16, 10, 10]              32\n",
            "           Conv2d-14             [-1, 32, 8, 8]           4,608\n",
            "             ReLU-15             [-1, 32, 8, 8]               0\n",
            "      BatchNorm2d-16             [-1, 32, 8, 8]              64\n",
            "           Conv2d-17             [-1, 10, 8, 8]             320\n",
            "             ReLU-18             [-1, 10, 8, 8]               0\n",
            "      BatchNorm2d-19             [-1, 10, 8, 8]              20\n",
            "        AvgPool2d-20             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 7,612\n",
            "Trainable params: 7,612\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.48\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.51\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT_FHOFBami1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in model.parameters():\n",
        "#   logger.info(i)\n",
        "#   break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1__x_SbrL7z3",
        "colab_type": "text"
      },
      "source": [
        "# Training and Testing\n",
        "\n",
        "Looking at logs can be boring, so we'll introduce **tqdm** progressbar to get cooler logs. \n",
        "\n",
        "Let's write train and test functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV8c9I01L9M_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_current_train_acc(model, train_loader):\n",
        "  model.eval()\n",
        "  train_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "      for data, target in train_loader:\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          output = model(data)\n",
        "          train_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "          pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "          correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "  train_loss /= len(train_loader.dataset)\n",
        "\n",
        "  logger.info('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "      train_loss, correct, len(train_loader.dataset),\n",
        "      100. * correct / len(train_loader.dataset)))\n",
        "  \n",
        "  train_acc = 100. * correct / len(train_loader.dataset)\n",
        "  return train_acc, train_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbkF2nN_LYIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# train_losses = []\n",
        "# test_losses = []\n",
        "# train_acc = []\n",
        "# test_acc = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, lambda_l1=0, train_acc=[], train_losses=[]):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    #train_losses.append(loss)\n",
        "\n",
        "    # L1 regularisation\n",
        "\n",
        "    l1 = 0\n",
        "    for p in model.parameters():\n",
        "      l1 += p.abs().sum()\n",
        "    loss += lambda_l1 * l1\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "    \n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Current_train_batch_accuracy={100*correct/processed:0.2f}')\n",
        "  current_train_acc, current_train_loss = get_current_train_acc(model, train_loader)\n",
        "  train_acc.append(current_train_acc)\n",
        "  train_losses.append(current_train_loss)\n",
        "  return train_acc, train_losses\n",
        "\n",
        "def test(model, device, test_loader, test_acc=[], test_losses=[]):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    logger.info('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))\n",
        "    return test_acc, test_losses\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drokW8wWODKq",
        "colab_type": "text"
      },
      "source": [
        "# Let's Train and test our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P23-o-NBFa0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def save_best_model(epochs, model, device, train_loader, optimizer, lambda_l1=0.0, scheduler):\n",
        "#   for epoch in range(EPOCHS):\n",
        "#     logger.info(f\" ***** EPOCH:{epoch} ***** \")\n",
        "#     train(model, device, train_loader, optimizer, epoch, lambda_l1)\n",
        "#     scheduler.step()\n",
        "#     test(model, device, test_loader)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p4iyxo0IdK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_best_train_test_acc(train_acc=[], test_acc=[]):\n",
        "  \"\"\"\n",
        "  Example:\n",
        "  train_acc_1=[96.5,98.7,99.2,99.3];test_acc_1=[97.2,98.5, 99.25, 99.2]\n",
        "  assert get_best_train_test_acc(train_acc_1, test_acc_1)==(99.2, 99.25)\n",
        "  \"\"\"\n",
        "  tr_te_acc_pairs = list(zip(train_acc, test_acc))\n",
        "  tr_te_acc_pairs_original = tr_te_acc_pairs[:]\n",
        "  tr_te_acc_pairs.sort(key = lambda x: x[1], reverse=True)\n",
        "  for tr_acc, te_acc in tr_te_acc_pairs:\n",
        "    if tr_acc > te_acc and tr_acc - te_acc >= 1:\n",
        "      tr_te_acc_pairs.remove((tr_acc, te_acc))\n",
        "  return tr_te_acc_pairs[0], tr_te_acc_pairs_original.index(tr_te_acc_pairs[0])+1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMo6bSgKYFJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(model, PATH='./test_model.pickle'):\n",
        "  \"\"\"\n",
        "   Save trained model at given PATH\n",
        "  \"\"\"\n",
        "  torch.save(model.state_dict(), PATH)\n",
        "  logger.info(f\"Model saved at {PATH}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iewpQKUSUUb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_acc_1=[96.5,98.7,99.2,99.3];test_acc_1=[97.2,98.5, 99.25, 99.2]\n",
        "get_best_train_test_acc(train_acc_1, test_acc_1)\n",
        "\n",
        "assert get_best_train_test_acc(train_acc_1, test_acc_1)==((99.2, 99.25),3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwZLjJpdcjv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_model(epochs, model, device, train_loader, test_loader, optimizer, lambda_l1, scheduler):\n",
        "  train_acc = []\n",
        "  train_losses = []\n",
        "  test_acc = []\n",
        "  test_losses = []\n",
        "  for epoch in range(EPOCHS):\n",
        "    logger.info(f\"[EPOCH:{epoch}]\")\n",
        "    train_acc, train_losses = train(model, device, train_loader, optimizer, lambda_l1, train_acc, train_losses)\n",
        "    scheduler.step()\n",
        "    test_acc, test_losses = test(model, device, test_loader, test_acc, test_losses)\n",
        "  return train_acc, train_losses, test_acc, test_losses\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE7n4kFFydW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "      # train_acc, train_losses, test_acc, test_losses = fit_model(epochs, model, device, train_loader, test_loader, optimizer, para, scheduler)\n",
        "      # (best_train_acc, best_test_acc), epoch = get_best_train_test_acc(train_acc, test_acc)\n",
        "      # logger.info(f\"For L1 lambda parameter {para} Best train Accuracy {best_train_acc}% and Best Test Accuracy {best_test_acc}% at Epoch {epoch}\")\n",
        "      # all_lambdal1_train_test_acc_from_best_epoch.append((best_train_acc, best_test_acc, para))\n",
        "      # temp_best_train_acc_list.append(best_train_acc)\n",
        "      # temp_best_test_acc_list.append(best_test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljNM8Om6vqjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def best_tr_te_acc_from_epoch(epochs, model, device, train_loader, test_loader, optimizer, lambda_l1=0, lambda_l2=0, scheduler=None):\n",
        "  temp_best_train_acc_list = []\n",
        "  temp_best_test_acc_list = []\n",
        "  all_lambdal1_train_test_acc_from_best_epoch =[]\n",
        "  train_acc, train_losses, test_acc, test_losses = fit_model(epochs, model, device, train_loader, test_loader, optimizer, lambda_l1=lambda_l1, scheduler=scheduler)\n",
        "  (best_train_acc, best_test_acc), epoch = get_best_train_test_acc(train_acc, test_acc)\n",
        "  logger.info(f\"\\n===================> For L1 lambda parameter {lambda_l1}, For L2 lambda parameter {lambda_l2}, Best train Accuracy {best_train_acc}% and Best Test Accuracy {best_test_acc}% at Epoch {epoch} <===================\\n\")\n",
        "  all_lambdal1_train_test_acc_from_best_epoch.append((best_train_acc, best_test_acc, lambda_l1, lambda_l2 ))\n",
        "  temp_best_train_acc_list.append(best_train_acc)\n",
        "  temp_best_test_acc_list.append(best_test_acc)\n",
        "  return temp_best_train_acc_list, temp_best_test_acc_list, all_lambdal1_train_test_acc_from_best_epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FViXBzUdwDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_grid_search(epochs, model, device, train_loader, test_loader, optimizer, scheduler, lambda_l1_range = [], lambda_l2_range = [], size = 20, l1_l2_trails=0):\n",
        "  best_lambdal1_train_acc = 0.0\n",
        "  best_lambdal1_test_acc = 0.0\n",
        "  best_lambdal1 = 0.0\n",
        "  all_lambdal1_train_test_acc_from_best_epoch = []\n",
        " \n",
        "\n",
        "  if lambda_l1_range and lambda_l2_range:\n",
        "    if lambda_l1_range[0]>lambda_l1_range[1] or lambda_l2_range[0]>lambda_l2_range[1]:\n",
        "      raise Exception(\"It should be => min<max\")\n",
        "    options_l1 = np.random.uniform(low=lambda_l1_range[0], high=lambda_l1_range[1], size=size)\n",
        "    options_l2 = np.random.uniform(low=lambda_l2_range[0], high=lambda_l2_range[1], size=size)\n",
        "    for i in range(l1_l2_trails):\n",
        "      l1_value = random.choice(options_l1)\n",
        "      l2_value = random.choice(options_l2)\n",
        "      logger.info(f\"\\n L1&L2 Trail:{i+1} - Model is getting trained with L1 regularisation parameter {l1_value} and L2 regularisation parameter {l2_value}\\n\")\n",
        "      model =  Net().to(device)\n",
        "      optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=l2_value)\n",
        "      scheduler = StepLR(optimizer, step_size=12, gamma=0.2)\n",
        "      temp_best_train_acc_list, temp_best_test_acc_list, all_lambdal1_train_test_acc_from_best_epoch = best_tr_te_acc_from_epoch(epochs, model, device, train_loader, test_loader, optimizer, lambda_l1=l1_value, lambda_l2=l2_value, scheduler=scheduler)\n",
        "    \n",
        "    (best_para_train_acc, best_para_test_acc), idx = get_best_train_test_acc(temp_best_train_acc_list, temp_best_test_acc_list)\n",
        "    idx -= 1\n",
        "    final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 = all_lambdal1_train_test_acc_from_best_epoch[idx]\n",
        "    logger.info(f\"\\n===================> final_best_train_acc: {final_best_train_acc}, final_best_test_acc: {final_best_test_acc}, final_best_lambda_l1: {final_best_lambda_l1} , final_best_lambda_l2: {final_best_lambda_l2} <===================\\n\")\n",
        "    return final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2\n",
        "\n",
        "\n",
        "  elif lambda_l1_range:\n",
        "    if lambda_l1_range[0]>lambda_l1_range[1]:\n",
        "      raise Exception(\"It should be => lambda_l1_range[0]<lambda_l1_range[1]\")\n",
        "    options = np.random.uniform(low=lambda_l1_range[0], high=lambda_l1_range[1], size=size)\n",
        "    for i, para in enumerate(options):\n",
        "      logger.info(f\"\\n L1 Trail:{i+1} - Model is getting trained with L1 regularisation parameter {para}\\n\")\n",
        "      model =  Net().to(device)\n",
        "      optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "      scheduler = StepLR(optimizer, step_size=12, gamma=0.2)\n",
        "      temp_best_train_acc_list, temp_best_test_acc_list, all_lambdal1_train_test_acc_from_best_epoch = best_tr_te_acc_from_epoch(epochs, model, device, train_loader, test_loader, optimizer, lambda_l1=para, lambda_l2=0, scheduler=scheduler)\n",
        "    (best_para_train_acc, best_para_test_acc), idx = get_best_train_test_acc(temp_best_train_acc_list, temp_best_test_acc_list)\n",
        "    idx -= 1\n",
        "    final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 = all_lambdal1_train_test_acc_from_best_epoch[idx]\n",
        "    logger.info(f\"\\n===================> final_best_train_acc: {final_best_train_acc}, final_best_test_acc: {final_best_test_acc}, final_best_lambda_l1: {final_best_lambda_l1} <===================\\n\")\n",
        "    return final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2\n",
        "\n",
        "  elif lambda_l2_range:\n",
        "    if lambda_l2_range[0]>lambda_l2_range[1]:\n",
        "      raise Exception(\"It should be => lambda_l2_range[0]<lambda_l2_range[1]\")\n",
        "    options = np.random.uniform(low=lambda_l2_range[0], high=lambda_l2_range[1], size=size)\n",
        "    for i, para in enumerate(options):\n",
        "      logger.info(f\"\\n L2 Trail:{i+1} - Model is getting trained with L2 regularisation parameter {para}\\n\")\n",
        "      model =  Net().to(device)\n",
        "      optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=para)\n",
        "      scheduler = StepLR(optimizer, step_size=12, gamma=0.2)\n",
        "      temp_best_train_acc_list, temp_best_test_acc_list, all_lambdal1_train_test_acc_from_best_epoch = best_tr_te_acc_from_epoch(epochs, model, device, train_loader, test_loader, optimizer=optimizer, lambda_l1=0, lambda_l2=para, scheduler=scheduler)\n",
        "    (best_para_train_acc, best_para_test_acc), idx = get_best_train_test_acc(temp_best_train_acc_list, temp_best_test_acc_list)\n",
        "    idx -= 1\n",
        "    final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 = all_lambdal1_train_test_acc_from_best_epoch[idx]\n",
        "    logger.info(f\"\\n===================> final_best_train_acc: {final_best_train_acc}, final_best_test_acc: {final_best_test_acc}, final_best_lambda_l2: {final_best_lambda_l2} <===================\\n\")\n",
        "    return final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2\n",
        "\n",
        "  else:\n",
        "    raise Exception(\"Select at least one parameter to search its mathematical space\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqPe1y_82y-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "EPOCHS = 15\n",
        "scheduler = StepLR(optimizer, step_size=12, gamma=0.2)\n",
        "# lambda_l1=0\n",
        "l1_l2_trails=50\n",
        "\n",
        "# para_grid_lambda = [[0,0.1],[0,0.01],[0,0.001],[0,0.0001]]\n",
        "#para_grid_lambda = [[0,0.0001], [0,0.001], [0,0.01],[0,0.1]]\n",
        "para_grid_lambda = [[0,0.0001], [0,0.001]]\n",
        "# para_grid_lambda = [[0,0.0001], [0,0.1]]\n",
        "results_lambda_l1 = []\n",
        "results_lambda_l2 = []\n",
        "results_lambda_l1_l2 = []\n",
        "size = 20 # Number of random choices in the given range"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9VolLll21-T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86f21558-b55a-4209-dccf-7daa2de754fb"
      },
      "source": [
        "\n",
        "# ## L1&L2 regularisation hyper parameter search\n",
        "\n",
        "# # l1 and l2 reg paras in same range given but can be given different ranges by writing little more sophisticated logic\n",
        "for para_range in para_grid_lambda:\n",
        "  logger.info(f\"\\n===================> Started - Trail on L1 & L2 reg parameters range - {para_range}, Number of para_ranges - {size}, , Number of trails per para_range - {l1_l2_trails}, Number of Epochs - {EPOCHS}<===================\\n\")\n",
        "  final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 = my_grid_search(EPOCHS, model, device, train_loader, test_loader, optimizer, scheduler, lambda_l1_range = para_range, lambda_l2_range = para_range, size = size, l1_l2_trails=l1_l2_trails)\n",
        "  results_lambda_l1_l2.append((final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2))\n",
        "  logger.info(f\"\\n===================> current results_lambda_l1_l2 - {results_lambda_l1_l2} <===================\\n\")\n",
        "  logger.info(f\"\\n===================> Completed - Trail on L1 and L2 reg parameters range - {para_range} <===================\\n\")\n",
        "\n",
        "logger.info(f\"\\n===================> L1 & L2 - Results of Coarse/finer grid search in various ranges - {para_grid_lambda} <===================\\n\")\n",
        "for final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 in results_lambda_l1_l2:\n",
        "  logger.info(f\"L1 reg parameter: {final_best_lambda_l1}, L2 reg parameter: {final_best_lambda_l2}, Train_acc: {final_best_train_acc}, Test_acc: {final_best_test_acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss=0.12660039961338043 Batch_id=468 Current_train_batch_accuracy=94.01: 100%|██████████| 469/469 [00:14<00:00, 31.42it/s]\n",
            "Loss=0.10420891642570496 Batch_id=468 Current_train_batch_accuracy=97.94: 100%|██████████| 469/469 [00:14<00:00, 31.95it/s]\n",
            "Loss=0.08869346976280212 Batch_id=468 Current_train_batch_accuracy=98.28: 100%|██████████| 469/469 [00:15<00:00, 31.15it/s]\n",
            "Loss=0.10045590996742249 Batch_id=468 Current_train_batch_accuracy=98.46: 100%|██████████| 469/469 [00:14<00:00, 31.28it/s]\n",
            "Loss=0.0811336413025856 Batch_id=468 Current_train_batch_accuracy=98.48: 100%|██████████| 469/469 [00:14<00:00, 31.36it/s]\n",
            "Loss=0.06163523718714714 Batch_id=468 Current_train_batch_accuracy=98.64: 100%|██████████| 469/469 [00:15<00:00, 31.12it/s]\n",
            "Loss=0.08621945977210999 Batch_id=468 Current_train_batch_accuracy=98.63: 100%|██████████| 469/469 [00:14<00:00, 31.33it/s]\n",
            "Loss=0.06197027489542961 Batch_id=468 Current_train_batch_accuracy=98.66: 100%|██████████| 469/469 [00:14<00:00, 31.27it/s]\n",
            "Loss=0.07102006673812866 Batch_id=468 Current_train_batch_accuracy=98.71: 100%|██████████| 469/469 [00:14<00:00, 31.35it/s]\n",
            "Loss=0.07961781322956085 Batch_id=468 Current_train_batch_accuracy=98.76: 100%|██████████| 469/469 [00:15<00:00, 31.13it/s]\n",
            "Loss=0.07943959534168243 Batch_id=468 Current_train_batch_accuracy=98.71: 100%|██████████| 469/469 [00:15<00:00, 31.12it/s]\n",
            "Loss=0.11983998119831085 Batch_id=468 Current_train_batch_accuracy=98.79: 100%|██████████| 469/469 [00:14<00:00, 31.32it/s]\n",
            "Loss=0.05753502994775772 Batch_id=468 Current_train_batch_accuracy=99.18: 100%|██████████| 469/469 [00:15<00:00, 31.06it/s]\n",
            "Loss=0.1161389872431755 Batch_id=468 Current_train_batch_accuracy=99.24: 100%|██████████| 469/469 [00:15<00:00, 31.17it/s]\n",
            "Loss=0.04796069860458374 Batch_id=468 Current_train_batch_accuracy=99.28: 100%|██████████| 469/469 [00:14<00:00, 31.35it/s]\n",
            "Loss=0.14808224141597748 Batch_id=468 Current_train_batch_accuracy=93.71: 100%|██████████| 469/469 [00:14<00:00, 31.63it/s]\n",
            "Loss=0.10361899435520172 Batch_id=468 Current_train_batch_accuracy=97.89: 100%|██████████| 469/469 [00:14<00:00, 31.77it/s]\n",
            "Loss=0.06604684889316559 Batch_id=468 Current_train_batch_accuracy=98.33: 100%|██████████| 469/469 [00:14<00:00, 31.40it/s]\n",
            "Loss=0.07388590276241302 Batch_id=468 Current_train_batch_accuracy=98.49: 100%|██████████| 469/469 [00:14<00:00, 31.58it/s]\n",
            "Loss=0.06208476051688194 Batch_id=468 Current_train_batch_accuracy=98.64: 100%|██████████| 469/469 [00:14<00:00, 31.64it/s]\n",
            "Loss=0.05546869710087776 Batch_id=468 Current_train_batch_accuracy=98.67: 100%|██████████| 469/469 [00:14<00:00, 32.27it/s]\n",
            "Loss=0.1281963586807251 Batch_id=468 Current_train_batch_accuracy=98.69: 100%|██████████| 469/469 [00:14<00:00, 33.08it/s]\n",
            "Loss=0.0733441486954689 Batch_id=468 Current_train_batch_accuracy=98.78: 100%|██████████| 469/469 [00:14<00:00, 33.15it/s]\n",
            "Loss=0.04233265295624733 Batch_id=468 Current_train_batch_accuracy=98.86: 100%|██████████| 469/469 [00:14<00:00, 33.09it/s]\n",
            "Loss=0.04704621061682701 Batch_id=468 Current_train_batch_accuracy=98.89: 100%|██████████| 469/469 [00:13<00:00, 33.70it/s]\n",
            "Loss=0.04147961735725403 Batch_id=468 Current_train_batch_accuracy=98.92: 100%|██████████| 469/469 [00:13<00:00, 33.57it/s]\n",
            "Loss=0.035818006843328476 Batch_id=468 Current_train_batch_accuracy=98.94: 100%|██████████| 469/469 [00:13<00:00, 33.92it/s]\n",
            "Loss=0.056696370244026184 Batch_id=468 Current_train_batch_accuracy=99.28: 100%|██████████| 469/469 [00:13<00:00, 33.73it/s]\n",
            "Loss=0.04874667897820473 Batch_id=468 Current_train_batch_accuracy=99.36: 100%|██████████| 469/469 [00:13<00:00, 33.75it/s]\n",
            "Loss=0.04024061933159828 Batch_id=468 Current_train_batch_accuracy=99.37: 100%|██████████| 469/469 [00:13<00:00, 33.97it/s]\n",
            "Loss=0.09406448900699615 Batch_id=468 Current_train_batch_accuracy=94.15: 100%|██████████| 469/469 [00:13<00:00, 34.01it/s]\n",
            "Loss=0.07632988691329956 Batch_id=468 Current_train_batch_accuracy=98.02: 100%|██████████| 469/469 [00:13<00:00, 33.97it/s]\n",
            "Loss=0.13235993683338165 Batch_id=468 Current_train_batch_accuracy=98.36: 100%|██████████| 469/469 [00:13<00:00, 34.45it/s]\n",
            "Loss=0.0386534258723259 Batch_id=468 Current_train_batch_accuracy=98.59: 100%|██████████| 469/469 [00:13<00:00, 34.57it/s]\n",
            "Loss=0.032886818051338196 Batch_id=468 Current_train_batch_accuracy=98.68: 100%|██████████| 469/469 [00:13<00:00, 34.48it/s]\n",
            "Loss=0.04306870698928833 Batch_id=468 Current_train_batch_accuracy=98.80: 100%|██████████| 469/469 [00:13<00:00, 34.31it/s]\n",
            "Loss=0.0613560676574707 Batch_id=468 Current_train_batch_accuracy=98.84: 100%|██████████| 469/469 [00:13<00:00, 34.73it/s]\n",
            "Loss=0.05125186964869499 Batch_id=468 Current_train_batch_accuracy=98.87: 100%|██████████| 469/469 [00:13<00:00, 34.66it/s]\n",
            "Loss=0.10002805292606354 Batch_id=468 Current_train_batch_accuracy=98.98: 100%|██████████| 469/469 [00:13<00:00, 34.10it/s]\n",
            "Loss=0.0428081639111042 Batch_id=468 Current_train_batch_accuracy=98.91: 100%|██████████| 469/469 [00:13<00:00, 34.41it/s]\n",
            "Loss=0.05824247747659683 Batch_id=468 Current_train_batch_accuracy=98.96: 100%|██████████| 469/469 [00:13<00:00, 34.22it/s]\n",
            "Loss=0.04206471145153046 Batch_id=468 Current_train_batch_accuracy=99.02: 100%|██████████| 469/469 [00:13<00:00, 34.18it/s]\n",
            "Loss=0.05950386822223663 Batch_id=468 Current_train_batch_accuracy=99.25: 100%|██████████| 469/469 [00:13<00:00, 33.60it/s]\n",
            "Loss=0.025827661156654358 Batch_id=468 Current_train_batch_accuracy=99.36: 100%|██████████| 469/469 [00:13<00:00, 34.84it/s]\n",
            "Loss=0.02797047607600689 Batch_id=468 Current_train_batch_accuracy=99.36: 100%|██████████| 469/469 [00:13<00:00, 34.87it/s]\n",
            "Loss=0.19919969141483307 Batch_id=468 Current_train_batch_accuracy=93.70: 100%|██████████| 469/469 [00:13<00:00, 34.88it/s]\n",
            "Loss=0.1750161349773407 Batch_id=468 Current_train_batch_accuracy=97.69: 100%|██████████| 469/469 [00:13<00:00, 34.79it/s]\n",
            "Loss=0.15413415431976318 Batch_id=468 Current_train_batch_accuracy=98.00: 100%|██████████| 469/469 [00:13<00:00, 34.58it/s]\n",
            "Loss=0.09767427295446396 Batch_id=468 Current_train_batch_accuracy=98.29: 100%|██████████| 469/469 [00:13<00:00, 34.54it/s]\n",
            "Loss=0.09620703011751175 Batch_id=468 Current_train_batch_accuracy=98.34: 100%|██████████| 469/469 [00:13<00:00, 35.00it/s]\n",
            "Loss=0.18368390202522278 Batch_id=468 Current_train_batch_accuracy=98.48: 100%|██████████| 469/469 [00:13<00:00, 34.90it/s]\n",
            "Loss=0.12587647140026093 Batch_id=468 Current_train_batch_accuracy=98.47: 100%|██████████| 469/469 [00:13<00:00, 34.23it/s]\n",
            "Loss=0.14233380556106567 Batch_id=468 Current_train_batch_accuracy=98.48: 100%|██████████| 469/469 [00:13<00:00, 34.72it/s]\n",
            "Loss=0.12017838656902313 Batch_id=468 Current_train_batch_accuracy=98.60: 100%|██████████| 469/469 [00:13<00:00, 34.87it/s]\n",
            "Loss=0.08583349734544754 Batch_id=468 Current_train_batch_accuracy=98.62: 100%|██████████| 469/469 [00:13<00:00, 34.47it/s]\n",
            "Loss=0.1427975296974182 Batch_id=468 Current_train_batch_accuracy=98.64: 100%|██████████| 469/469 [00:13<00:00, 34.69it/s]\n",
            "Loss=0.1201711893081665 Batch_id=468 Current_train_batch_accuracy=98.64: 100%|██████████| 469/469 [00:13<00:00, 34.87it/s]\n",
            "Loss=0.07923005521297455 Batch_id=468 Current_train_batch_accuracy=99.08: 100%|██████████| 469/469 [00:13<00:00, 34.67it/s]\n",
            "Loss=0.16441617906093597 Batch_id=468 Current_train_batch_accuracy=99.23: 100%|██████████| 469/469 [00:13<00:00, 35.00it/s]\n",
            "Loss=0.07787555456161499 Batch_id=468 Current_train_batch_accuracy=99.23: 100%|██████████| 469/469 [00:13<00:00, 34.52it/s]\n",
            "Loss=0.11040212959051132 Batch_id=468 Current_train_batch_accuracy=93.31: 100%|██████████| 469/469 [00:13<00:00, 34.86it/s]\n",
            "Loss=0.11620265245437622 Batch_id=468 Current_train_batch_accuracy=97.96: 100%|██████████| 469/469 [00:13<00:00, 34.49it/s]\n",
            "Loss=0.18558917939662933 Batch_id=468 Current_train_batch_accuracy=98.23: 100%|██████████| 469/469 [00:13<00:00, 34.55it/s]\n",
            "Loss=0.06004492938518524 Batch_id=468 Current_train_batch_accuracy=98.47: 100%|██████████| 469/469 [00:13<00:00, 34.86it/s]\n",
            "Loss=0.11260496079921722 Batch_id=468 Current_train_batch_accuracy=98.60: 100%|██████████| 469/469 [00:13<00:00, 34.59it/s]\n",
            "Loss=0.08386901021003723 Batch_id=468 Current_train_batch_accuracy=98.68: 100%|██████████| 469/469 [00:13<00:00, 34.39it/s]\n",
            "Loss=0.047677673399448395 Batch_id=468 Current_train_batch_accuracy=98.64: 100%|██████████| 469/469 [00:13<00:00, 34.76it/s]\n",
            "Loss=0.05910821259021759 Batch_id=468 Current_train_batch_accuracy=98.72: 100%|██████████| 469/469 [00:13<00:00, 34.02it/s]\n",
            "Loss=0.037192050367593765 Batch_id=468 Current_train_batch_accuracy=98.80: 100%|██████████| 469/469 [00:13<00:00, 34.70it/s]\n",
            "Loss=0.15472985804080963 Batch_id=468 Current_train_batch_accuracy=98.83: 100%|██████████| 469/469 [00:13<00:00, 34.96it/s]\n",
            "Loss=0.047155287116765976 Batch_id=468 Current_train_batch_accuracy=98.83: 100%|██████████| 469/469 [00:13<00:00, 35.24it/s]\n",
            "Loss=0.04545465484261513 Batch_id=468 Current_train_batch_accuracy=98.83: 100%|██████████| 469/469 [00:13<00:00, 34.89it/s]\n",
            "Loss=0.04913559556007385 Batch_id=468 Current_train_batch_accuracy=99.23: 100%|██████████| 469/469 [00:13<00:00, 35.04it/s]\n",
            "Loss=0.045728810131549835 Batch_id=468 Current_train_batch_accuracy=99.26: 100%|██████████| 469/469 [00:13<00:00, 35.48it/s]\n",
            "Loss=0.052567265927791595 Batch_id=468 Current_train_batch_accuracy=99.31: 100%|██████████| 469/469 [00:13<00:00, 35.27it/s]\n",
            "Loss=0.14640256762504578 Batch_id=468 Current_train_batch_accuracy=94.23: 100%|██████████| 469/469 [00:13<00:00, 35.50it/s]\n",
            "Loss=0.11276953667402267 Batch_id=468 Current_train_batch_accuracy=97.89: 100%|██████████| 469/469 [00:13<00:00, 35.37it/s]\n",
            "Loss=0.08736872673034668 Batch_id=468 Current_train_batch_accuracy=98.28: 100%|██████████| 469/469 [00:13<00:00, 34.55it/s]\n",
            "Loss=0.11746261268854141 Batch_id=468 Current_train_batch_accuracy=98.47: 100%|██████████| 469/469 [00:13<00:00, 35.64it/s]\n",
            "Loss=0.06704813241958618 Batch_id=468 Current_train_batch_accuracy=98.52: 100%|██████████| 469/469 [00:13<00:00, 35.02it/s]\n",
            "Loss=0.13158410787582397 Batch_id=468 Current_train_batch_accuracy=98.56: 100%|██████████| 469/469 [00:13<00:00, 34.88it/s]\n",
            "Loss=0.15957984328269958 Batch_id=468 Current_train_batch_accuracy=98.65: 100%|██████████| 469/469 [00:13<00:00, 35.49it/s]\n",
            "Loss=0.10597831010818481 Batch_id=468 Current_train_batch_accuracy=98.73: 100%|██████████| 469/469 [00:13<00:00, 35.52it/s]\n",
            "Loss=0.11449555307626724 Batch_id=468 Current_train_batch_accuracy=98.75: 100%|██████████| 469/469 [00:13<00:00, 35.29it/s]\n",
            "Loss=0.0866471529006958 Batch_id=468 Current_train_batch_accuracy=98.70: 100%|██████████| 469/469 [00:13<00:00, 35.52it/s]\n",
            "Loss=0.18107041716575623 Batch_id=468 Current_train_batch_accuracy=98.75: 100%|██████████| 469/469 [00:13<00:00, 35.62it/s]\n",
            "Loss=0.0593465194106102 Batch_id=468 Current_train_batch_accuracy=98.82: 100%|██████████| 469/469 [00:13<00:00, 35.16it/s]\n",
            "Loss=0.05911516770720482 Batch_id=468 Current_train_batch_accuracy=99.21: 100%|██████████| 469/469 [00:13<00:00, 35.83it/s]\n",
            "Loss=0.05840079486370087 Batch_id=468 Current_train_batch_accuracy=99.32: 100%|██████████| 469/469 [00:13<00:00, 35.70it/s]\n",
            "Loss=0.05776534974575043 Batch_id=468 Current_train_batch_accuracy=99.30: 100%|██████████| 469/469 [00:13<00:00, 35.71it/s]\n",
            "Loss=0.10094726085662842 Batch_id=468 Current_train_batch_accuracy=93.22: 100%|██████████| 469/469 [00:13<00:00, 34.77it/s]\n",
            "Loss=0.12872768938541412 Batch_id=468 Current_train_batch_accuracy=97.75: 100%|██████████| 469/469 [00:13<00:00, 35.57it/s]\n",
            "Loss=0.054418303072452545 Batch_id=468 Current_train_batch_accuracy=98.10: 100%|██████████| 469/469 [00:13<00:00, 35.19it/s]\n",
            "Loss=0.1033569723367691 Batch_id=468 Current_train_batch_accuracy=98.36: 100%|██████████| 469/469 [00:13<00:00, 35.08it/s]\n",
            "Loss=0.08130160719156265 Batch_id=468 Current_train_batch_accuracy=98.45: 100%|██████████| 469/469 [00:13<00:00, 35.62it/s]\n",
            "Loss=0.062063343822956085 Batch_id=468 Current_train_batch_accuracy=98.55: 100%|██████████| 469/469 [00:13<00:00, 35.71it/s]\n",
            "Loss=0.07217726111412048 Batch_id=468 Current_train_batch_accuracy=98.61: 100%|██████████| 469/469 [00:13<00:00, 35.77it/s]\n",
            "Loss=0.12634220719337463 Batch_id=468 Current_train_batch_accuracy=98.68: 100%|██████████| 469/469 [00:13<00:00, 35.62it/s]\n",
            "Loss=0.0737571120262146 Batch_id=468 Current_train_batch_accuracy=98.74: 100%|██████████| 469/469 [00:13<00:00, 35.52it/s]\n",
            "Loss=0.07381407171487808 Batch_id=468 Current_train_batch_accuracy=98.79: 100%|██████████| 469/469 [00:13<00:00, 35.64it/s]\n",
            "Loss=0.08782301843166351 Batch_id=468 Current_train_batch_accuracy=98.84: 100%|██████████| 469/469 [00:13<00:00, 35.14it/s]\n",
            "Loss=0.07216671109199524 Batch_id=468 Current_train_batch_accuracy=98.83: 100%|██████████| 469/469 [00:13<00:00, 35.36it/s]\n",
            "Loss=0.056318558752536774 Batch_id=468 Current_train_batch_accuracy=99.12: 100%|██████████| 469/469 [00:13<00:00, 35.98it/s]\n",
            "Loss=0.03442950174212456 Batch_id=468 Current_train_batch_accuracy=99.22: 100%|██████████| 469/469 [00:13<00:00, 35.24it/s]\n",
            "Loss=0.03343846648931503 Batch_id=468 Current_train_batch_accuracy=99.33: 100%|██████████| 469/469 [00:13<00:00, 35.90it/s]\n",
            "Loss=0.1628846377134323 Batch_id=468 Current_train_batch_accuracy=94.05: 100%|██████████| 469/469 [00:13<00:00, 34.77it/s]\n",
            "Loss=0.06559331715106964 Batch_id=468 Current_train_batch_accuracy=97.99: 100%|██████████| 469/469 [00:14<00:00, 33.10it/s]\n",
            "Loss=0.051881495863199234 Batch_id=468 Current_train_batch_accuracy=98.34: 100%|██████████| 469/469 [00:14<00:00, 32.58it/s]\n",
            "Loss=0.06460945308208466 Batch_id=468 Current_train_batch_accuracy=98.56: 100%|██████████| 469/469 [00:13<00:00, 33.76it/s]\n",
            "Loss=0.042718831449747086 Batch_id=468 Current_train_batch_accuracy=98.65: 100%|██████████| 469/469 [00:13<00:00, 34.36it/s]\n",
            "Loss=0.11025583744049072 Batch_id=468 Current_train_batch_accuracy=98.65: 100%|██████████| 469/469 [00:14<00:00, 33.44it/s]\n",
            "Loss=0.08785753697156906 Batch_id=468 Current_train_batch_accuracy=98.78: 100%|██████████| 469/469 [00:13<00:00, 34.21it/s]\n",
            "Loss=0.0519927479326725 Batch_id=468 Current_train_batch_accuracy=98.82: 100%|██████████| 469/469 [00:13<00:00, 34.18it/s]\n",
            "Loss=0.08492368459701538 Batch_id=468 Current_train_batch_accuracy=98.91: 100%|██████████| 469/469 [00:13<00:00, 34.96it/s]\n",
            "Loss=0.12612232565879822 Batch_id=468 Current_train_batch_accuracy=98.86: 100%|██████████| 469/469 [00:13<00:00, 35.20it/s]\n",
            "Loss=0.06853831559419632 Batch_id=468 Current_train_batch_accuracy=98.90: 100%|██████████| 469/469 [00:13<00:00, 34.70it/s]\n",
            "Loss=0.11157143115997314 Batch_id=468 Current_train_batch_accuracy=98.94: 100%|██████████| 469/469 [00:13<00:00, 34.60it/s]\n",
            "Loss=0.06735195219516754 Batch_id=468 Current_train_batch_accuracy=99.28: 100%|██████████| 469/469 [00:13<00:00, 34.28it/s]\n",
            "Loss=0.030362719669938087 Batch_id=468 Current_train_batch_accuracy=99.41: 100%|██████████| 469/469 [00:13<00:00, 34.78it/s]\n",
            "Loss=0.07872775197029114 Batch_id=468 Current_train_batch_accuracy=99.33: 100%|██████████| 469/469 [00:13<00:00, 34.16it/s]\n",
            "Loss=0.10625981539487839 Batch_id=468 Current_train_batch_accuracy=94.36: 100%|██████████| 469/469 [00:13<00:00, 34.56it/s]\n",
            "Loss=0.07463235408067703 Batch_id=468 Current_train_batch_accuracy=98.03: 100%|██████████| 469/469 [00:13<00:00, 34.88it/s]\n",
            "Loss=0.04218590259552002 Batch_id=468 Current_train_batch_accuracy=98.42: 100%|██████████| 469/469 [00:13<00:00, 34.37it/s]\n",
            "Loss=0.10376670956611633 Batch_id=468 Current_train_batch_accuracy=98.51: 100%|██████████| 469/469 [00:13<00:00, 35.07it/s]\n",
            "Loss=0.08059603720903397 Batch_id=468 Current_train_batch_accuracy=98.69: 100%|██████████| 469/469 [00:13<00:00, 35.01it/s]\n",
            "Loss=0.02353048138320446 Batch_id=468 Current_train_batch_accuracy=98.81: 100%|██████████| 469/469 [00:13<00:00, 34.66it/s]\n",
            "Loss=0.026199765503406525 Batch_id=468 Current_train_batch_accuracy=98.80: 100%|██████████| 469/469 [00:13<00:00, 34.90it/s]\n",
            "Loss=0.13297538459300995 Batch_id=468 Current_train_batch_accuracy=98.90: 100%|██████████| 469/469 [00:13<00:00, 35.24it/s]\n",
            "Loss=0.037627775222063065 Batch_id=468 Current_train_batch_accuracy=98.93: 100%|██████████| 469/469 [00:13<00:00, 35.14it/s]\n",
            "Loss=0.03764955326914787 Batch_id=468 Current_train_batch_accuracy=98.88: 100%|██████████| 469/469 [00:13<00:00, 34.81it/s]\n",
            "Loss=0.050560519099235535 Batch_id=468 Current_train_batch_accuracy=98.94: 100%|██████████| 469/469 [00:13<00:00, 34.68it/s]\n",
            "Loss=0.027794720605015755 Batch_id=468 Current_train_batch_accuracy=98.98: 100%|██████████| 469/469 [00:13<00:00, 35.39it/s]\n",
            "Loss=0.017336353659629822 Batch_id=468 Current_train_batch_accuracy=99.29: 100%|██████████| 469/469 [00:13<00:00, 34.72it/s]\n",
            "Loss=0.030053064227104187 Batch_id=468 Current_train_batch_accuracy=99.34: 100%|██████████| 469/469 [00:13<00:00, 35.68it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMCFxeAKOB53",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6a5167c5-9d52-44de-8e10-bc49681d2151"
      },
      "source": [
        "\"\"\"model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "EPOCHS = 15\n",
        "scheduler = StepLR(optimizer, step_size=12, gamma=0.2)\n",
        "# lambda_l1=0\n",
        "l1_l2_trails=50\n",
        "\n",
        "# para_grid_lambda = [[0,0.1],[0,0.01],[0,0.001],[0,0.0001]]\n",
        "para_grid_lambda = [[0,0.0001], [0,0.001], [0,0.01],[0,0.1]]\n",
        "# para_grid_lambda = [[0,0.0001], [0,0.1]]\n",
        "results_lambda_l1 = []\n",
        "results_lambda_l2 = []\n",
        "results_lambda_l1_l2 = []\n",
        "size = 20 # Number of random choices in the given range\n",
        "\n",
        "\n",
        "## L1 regularisation hyper parameter search\n",
        "\n",
        "for para_range in para_grid_lambda:\n",
        "  logger.info(f\"\\n===================> Started - Trail on L1 reg parameters range - {para_range}, Number of trails - {size}, Number of Epochs - {EPOCHS} <===================\\n\")\n",
        "  final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 = my_grid_search(EPOCHS, model, device, train_loader, test_loader, optimizer, scheduler, lambda_l1_range = para_range, lambda_l2_range = [], size = size)\n",
        "  results_lambda_l1.append((final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2))\n",
        "  logger.info(f\"\\n===================> current results_lambda_l1 - {results_lambda_l1} <===================\\n\")\n",
        "  logger.info(f\"\\n===================> Completed - Trail on L1 reg parameters range - {para_range} <===================\\n\")\n",
        "\n",
        "logger.info(f\"\\n===================> L1 - Results of Coarse/finer grid search in various ranges - {para_grid_lambda}<===================\\n\")\n",
        "for final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 in results_lambda_l1:\n",
        "  logger.info(f\"L1 reg parameter: {final_best_lambda_l1}, L2 reg parameter: {final_best_lambda_l2}, Train_acc: {final_best_train_acc}, Test_acc: {final_best_test_acc}\")\n",
        "\n",
        "# ## L2 regularisation hyper parameter search\n",
        "\n",
        "# for para_range in para_grid_lambda:\n",
        "#   logger.info(f\"\\n===================> Started - Trail on L2 reg parameters range - {para_range}, Number of trails - {size}, Number of Epochs - {EPOCHS}<===================\\n\")\n",
        "#   final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 = my_grid_search(EPOCHS, model, device, train_loader, test_loader, optimizer, scheduler, lambda_l1_range = [], lambda_l2_range = para_range, size = size)\n",
        "#   results_lambda_l2.append((final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2))\n",
        "#   logger.info(f\"\\n===================> current results_lambda_l2 - {results_lambda_l2} <===================\\n\")\n",
        "#   logger.info(f\"\\n===================> Completed - Trail on L2 reg parameters range - {para_range} <===================\\n\")\n",
        "\n",
        "# logger.info(f\"\\n===================> L2 - Results of Coarse/finer grid search in various ranges - {para_grid_lambda}<===================\\n\")\n",
        "# for final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 in results_lambda_l2:\n",
        "#   logger.info(f\"L1 reg parameter: {final_best_lambda_l1}, L2 reg parameter: {final_best_lambda_l2}, Train_acc: {final_best_train_acc}, Test_acc: {final_best_test_acc}\")\n",
        "\n",
        "# ## L1&L2 regularisation hyper parameter search\n",
        "\n",
        "# # l1 and l2 reg paras in same range given but can be given different ranges by writing little more sophisticated logic\n",
        "# for para_range in para_grid_lambda:\n",
        "#   logger.info(f\"\\n===================> Started - Trail on L1 & L2 reg parameters range - {para_range}, Number of para_ranges - {size}, , Number of trails per para_range - {l1_l2_trails}, Number of Epochs - {EPOCHS}<===================\\n\")\n",
        "#   final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 = my_grid_search(EPOCHS, model, device, train_loader, test_loader, optimizer, scheduler, lambda_l1_range = para_range, lambda_l2_range = para_range, size = size, l1_l2_trails=l1_l2_trails)\n",
        "#   results_lambda_l1_l2.append((final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2))\n",
        "#   logger.info(f\"\\n===================> current results_lambda_l1_l2 - {results_lambda_l1_l2} <===================\\n\")\n",
        "#   logger.info(f\"\\n===================> Completed - Trail on L1 and L2 reg parameters range - {para_range} <===================\\n\")\n",
        "\n",
        "# logger.info(f\"\\n===================> L1 & L2 - Results of Coarse/finer grid search in various ranges - {para_grid_lambda} <===================\\n\")\n",
        "# for final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 in results_lambda_l1_l2:\n",
        "#   logger.info(f\"L1 reg parameter: {final_best_lambda_l1}, L2 reg parameter: {final_best_lambda_l2}, Train_acc: {final_best_train_acc}, Test_acc: {final_best_test_acc}\")\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss=0.12899385392665863 Batch_id=468 Current_train_batch_accuracy=94.00: 100%|██████████| 469/469 [00:14<00:00, 31.27it/s]\n",
            "Loss=0.11819936335086823 Batch_id=468 Current_train_batch_accuracy=97.92: 100%|██████████| 469/469 [00:14<00:00, 31.53it/s]\n",
            "Loss=0.12428629398345947 Batch_id=468 Current_train_batch_accuracy=98.31: 100%|██████████| 469/469 [00:14<00:00, 31.65it/s]\n",
            "Loss=0.09569384157657623 Batch_id=468 Current_train_batch_accuracy=98.42: 100%|██████████| 469/469 [00:14<00:00, 31.46it/s]\n",
            "Loss=0.1254483014345169 Batch_id=468 Current_train_batch_accuracy=98.47: 100%|██████████| 469/469 [00:14<00:00, 31.45it/s]\n",
            "Loss=0.08706681430339813 Batch_id=468 Current_train_batch_accuracy=98.56: 100%|██████████| 469/469 [00:14<00:00, 31.69it/s]\n",
            "Loss=0.1018138974905014 Batch_id=468 Current_train_batch_accuracy=98.65: 100%|██████████| 469/469 [00:14<00:00, 31.34it/s]\n",
            "Loss=0.0737680196762085 Batch_id=468 Current_train_batch_accuracy=98.66: 100%|██████████| 469/469 [00:14<00:00, 31.36it/s]\n",
            "Loss=0.1044887825846672 Batch_id=468 Current_train_batch_accuracy=98.76: 100%|██████████| 469/469 [00:14<00:00, 31.37it/s]\n",
            "Loss=0.0960947573184967 Batch_id=468 Current_train_batch_accuracy=98.77: 100%|██████████| 469/469 [00:14<00:00, 31.90it/s]\n",
            "Loss=0.09928031265735626 Batch_id=468 Current_train_batch_accuracy=98.79: 100%|██████████| 469/469 [00:14<00:00, 32.00it/s]\n",
            "Loss=0.11418326199054718 Batch_id=468 Current_train_batch_accuracy=98.76: 100%|██████████| 469/469 [00:14<00:00, 31.82it/s]\n",
            "Loss=0.07967740297317505 Batch_id=468 Current_train_batch_accuracy=99.21: 100%|██████████| 469/469 [00:14<00:00, 32.66it/s]\n",
            "Loss=0.14698246121406555 Batch_id=468 Current_train_batch_accuracy=99.31: 100%|██████████| 469/469 [00:14<00:00, 32.53it/s]\n",
            "Loss=0.05912402272224426 Batch_id=468 Current_train_batch_accuracy=99.33: 100%|██████████| 469/469 [00:14<00:00, 32.28it/s]\n",
            "Loss=0.14087355136871338 Batch_id=468 Current_train_batch_accuracy=93.59: 100%|██████████| 469/469 [00:14<00:00, 32.26it/s]\n",
            "Loss=0.07513612508773804 Batch_id=468 Current_train_batch_accuracy=97.89: 100%|██████████| 469/469 [00:14<00:00, 31.58it/s]\n",
            "Loss=0.057402826845645905 Batch_id=468 Current_train_batch_accuracy=98.36: 100%|██████████| 469/469 [00:14<00:00, 31.59it/s]\n",
            "Loss=0.06607360392808914 Batch_id=468 Current_train_batch_accuracy=98.46: 100%|██████████| 469/469 [00:14<00:00, 32.41it/s]\n",
            "Loss=0.05662398412823677 Batch_id=468 Current_train_batch_accuracy=98.65: 100%|██████████| 469/469 [00:14<00:00, 32.88it/s]\n",
            "Loss=0.05441301316022873 Batch_id=468 Current_train_batch_accuracy=98.74: 100%|██████████| 469/469 [00:14<00:00, 31.76it/s]\n",
            "Loss=0.12726181745529175 Batch_id=468 Current_train_batch_accuracy=98.78: 100%|██████████| 469/469 [00:14<00:00, 32.18it/s]\n",
            "Loss=0.06195344030857086 Batch_id=468 Current_train_batch_accuracy=98.78: 100%|██████████| 469/469 [00:14<00:00, 32.23it/s]\n",
            "Loss=0.04053204506635666 Batch_id=468 Current_train_batch_accuracy=98.87: 100%|██████████| 469/469 [00:14<00:00, 32.37it/s]\n",
            "Loss=0.03821466863155365 Batch_id=468 Current_train_batch_accuracy=98.96: 100%|██████████| 469/469 [00:14<00:00, 32.36it/s]\n",
            "Loss=0.04000892862677574 Batch_id=468 Current_train_batch_accuracy=99.03: 100%|██████████| 469/469 [00:14<00:00, 32.15it/s]\n",
            "Loss=0.04338154196739197 Batch_id=468 Current_train_batch_accuracy=98.93: 100%|██████████| 469/469 [00:14<00:00, 31.95it/s]\n",
            "Loss=0.05549437552690506 Batch_id=468 Current_train_batch_accuracy=99.28: 100%|██████████| 469/469 [00:14<00:00, 32.30it/s]\n",
            "Loss=0.04691369831562042 Batch_id=468 Current_train_batch_accuracy=99.44: 100%|██████████| 469/469 [00:14<00:00, 32.43it/s]\n",
            "Loss=0.03210501745343208 Batch_id=468 Current_train_batch_accuracy=99.36: 100%|██████████| 469/469 [00:14<00:00, 32.01it/s]\n",
            "Loss=0.1432042419910431 Batch_id=468 Current_train_batch_accuracy=94.06: 100%|██████████| 469/469 [00:14<00:00, 32.01it/s]\n",
            "Loss=0.0960926041007042 Batch_id=468 Current_train_batch_accuracy=98.00: 100%|██████████| 469/469 [00:14<00:00, 32.33it/s]\n",
            "Loss=0.18325373530387878 Batch_id=468 Current_train_batch_accuracy=98.28: 100%|██████████| 469/469 [00:14<00:00, 32.41it/s]\n",
            "Loss=0.08076807111501694 Batch_id=468 Current_train_batch_accuracy=98.48: 100%|██████████| 469/469 [00:14<00:00, 32.34it/s]\n",
            "Loss=0.07596690952777863 Batch_id=468 Current_train_batch_accuracy=98.59: 100%|██████████| 469/469 [00:14<00:00, 32.36it/s]\n",
            "Loss=0.08143950998783112 Batch_id=468 Current_train_batch_accuracy=98.66: 100%|██████████| 469/469 [00:14<00:00, 31.91it/s]\n",
            "Loss=0.09490758180618286 Batch_id=468 Current_train_batch_accuracy=98.66: 100%|██████████| 469/469 [00:14<00:00, 32.03it/s]\n",
            "Loss=0.09460514038801193 Batch_id=468 Current_train_batch_accuracy=98.66: 100%|██████████| 469/469 [00:14<00:00, 32.27it/s]\n",
            "Loss=0.12492422759532928 Batch_id=468 Current_train_batch_accuracy=98.77: 100%|██████████| 469/469 [00:14<00:00, 32.72it/s]\n",
            "Loss=0.09444308280944824 Batch_id=468 Current_train_batch_accuracy=98.71: 100%|██████████| 469/469 [00:14<00:00, 32.25it/s]\n",
            "Loss=0.09489805996417999 Batch_id=468 Current_train_batch_accuracy=98.76: 100%|██████████| 469/469 [00:14<00:00, 31.60it/s]\n",
            "Loss=0.06711484491825104 Batch_id=468 Current_train_batch_accuracy=98.81: 100%|██████████| 469/469 [00:14<00:00, 31.59it/s]\n",
            "Loss=0.10211820900440216 Batch_id=468 Current_train_batch_accuracy=99.17: 100%|██████████| 469/469 [00:14<00:00, 32.09it/s]\n",
            "Loss=0.06445928663015366 Batch_id=468 Current_train_batch_accuracy=99.32: 100%|██████████| 469/469 [00:14<00:00, 32.46it/s]\n",
            "Loss=0.06113351136445999 Batch_id=468 Current_train_batch_accuracy=99.31: 100%|██████████| 469/469 [00:14<00:00, 32.34it/s]\n",
            "Loss=0.18868161737918854 Batch_id=468 Current_train_batch_accuracy=93.60: 100%|██████████| 469/469 [00:14<00:00, 32.36it/s]\n",
            "Loss=0.13280433416366577 Batch_id=468 Current_train_batch_accuracy=97.74: 100%|██████████| 469/469 [00:14<00:00, 32.47it/s]\n",
            "Loss=0.12690205872058868 Batch_id=468 Current_train_batch_accuracy=98.08: 100%|██████████| 469/469 [00:14<00:00, 32.50it/s]\n",
            "Loss=0.11787500977516174 Batch_id=468 Current_train_batch_accuracy=98.31: 100%|██████████| 469/469 [00:14<00:00, 32.44it/s]\n",
            "Loss=0.09175001084804535 Batch_id=468 Current_train_batch_accuracy=98.43: 100%|██████████| 469/469 [00:14<00:00, 32.38it/s]\n",
            "Loss=0.11794725060462952 Batch_id=468 Current_train_batch_accuracy=98.55: 100%|██████████| 469/469 [00:14<00:00, 32.30it/s]\n",
            "Loss=0.10896922647953033 Batch_id=468 Current_train_batch_accuracy=98.51: 100%|██████████| 469/469 [00:14<00:00, 32.55it/s]\n",
            "Loss=0.09282730519771576 Batch_id=468 Current_train_batch_accuracy=98.62: 100%|██████████| 469/469 [00:14<00:00, 32.25it/s]\n",
            "Loss=0.0884542465209961 Batch_id=468 Current_train_batch_accuracy=98.71: 100%|██████████| 469/469 [00:14<00:00, 31.76it/s]\n",
            "Loss=0.09058757871389389 Batch_id=468 Current_train_batch_accuracy=98.66: 100%|██████████| 469/469 [00:14<00:00, 32.16it/s]\n",
            "Loss=0.12048055231571198 Batch_id=468 Current_train_batch_accuracy=98.66: 100%|██████████| 469/469 [00:14<00:00, 32.25it/s]\n",
            "Loss=0.10965500771999359 Batch_id=468 Current_train_batch_accuracy=98.72: 100%|██████████| 469/469 [00:14<00:00, 31.96it/s]\n",
            "Loss=0.06403367221355438 Batch_id=468 Current_train_batch_accuracy=99.14: 100%|██████████| 469/469 [00:14<00:00, 32.72it/s]\n",
            "Loss=0.14821267127990723 Batch_id=468 Current_train_batch_accuracy=99.25: 100%|██████████| 469/469 [00:14<00:00, 32.59it/s]\n",
            "Loss=0.055797889828681946 Batch_id=426 Current_train_batch_accuracy=99.28:  90%|█████████ | 424/469 [00:13<00:01, 31.79it/s]"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}